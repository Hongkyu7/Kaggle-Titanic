{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv('train.csv', na_values=['', ' ', 'na', 'nan'])\n",
    "df_test_raw = pd.read_csv('test.csv', na_values=['', ' ', 'na', 'nan'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "PassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train_raw.dtypes)\n",
    "\n",
    "##### 결측치 개수 확인 ######\n",
    "df_train_raw.isna().sum()\n",
    "# 891개 Data\n",
    "# 결측치 Age: 177개, Cabin: 687개, Embarked: 2개\n",
    "df_test_raw.isna().sum()\n",
    "# 418개 Data\n",
    "# 결측치 Age: 86개, Fare: 1개 Cabin: 327개\n",
    "###########################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, feature_list, method='pandas', nan_drop_boolean='True', original_feature_drop_boolean='True'):\n",
    "\n",
    "    p_df = df.copy()\n",
    "\n",
    "    if method == 'sklearn': # Using scikit learn\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        one_hot_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "        for feature in feature_list:\n",
    "            p_df[feature] = p_df[feature].astype(str)\n",
    "            element_name = list(set(p_df[feature]))\n",
    "            exist_nan = False\n",
    "            if 'nan' in element_name: exist_nan = True\n",
    "\n",
    "            label_encoded = label_encoder.fit_transform(p_df[feature])\n",
    "            one_hot_encoded = one_hot_encoder.fit_transform(p_df[feature].to_numpy().reshape(-1,1))\n",
    "\n",
    "            df_one_hot_encoded = pd.DataFrame(one_hot_encoded)\n",
    "            p_df = pd.concat([p_df,df_one_hot_encoded], axis=1)\n",
    "\n",
    "            dict_col_name = {}\n",
    "            for i in range(len(element_name)):\n",
    "                dict_col_name[i] = feature + '_' + p_df[p_df[i] == 1][feature].iloc[0]\n",
    "\n",
    "            p_df.rename(columns=dict_col_name, inplace=True)\n",
    "\n",
    "            if nan_drop_boolean and exist_nan: p_df.drop([feature + '_nan'], axis=1, inplace=True)\n",
    "            if original_feature_drop_boolean: p_df.drop([feature], axis=1, inplace=True)\n",
    "\n",
    "    else: # Default - pandas get_dummies\n",
    "        for feature in feature_list:\n",
    "            df_one_hot_encoded = pd.get_dummies(p_df[feature], dummy_na=not(nan_drop_boolean))\n",
    "            df_one_hot_encoded = df_one_hot_encoded.astype(float)\n",
    "\n",
    "            element_name = df_one_hot_encoded.columns.to_list()\n",
    "            element_name_mod = [feature + '_' + str(i) for i in element_name]\n",
    "\n",
    "            dict_col_name = dict(zip(element_name, element_name_mod))\n",
    "\n",
    "            df_one_hot_encoded.rename(columns=dict_col_name, inplace=True)\n",
    "\n",
    "            p_df = pd.concat([p_df, df_one_hot_encoded], axis=1)\n",
    "\n",
    "            if original_feature_drop_boolean: p_df.drop([feature], axis=1, inplace=True)\n",
    "\n",
    "    return p_df\n",
    "\n",
    "\n",
    "def cabin_only_letter(df, feature_return, original_feature_drop_boolean='True'):\n",
    "    p_df = df.copy()\n",
    "    p_df['Cabin_dtype'] = list(map(lambda x: type(x).__name__, p_df['Cabin']))\n",
    "    p_df[feature_return] = p_df['Cabin'].copy()\n",
    "    p_df.loc[p_df['Cabin_dtype'] == 'str', 'Cabin_str'] = list(map(lambda x: x[0], p_df.loc[p_df['Cabin_dtype'] == 'str', 'Cabin_str']))\n",
    "    df[feature_return] = p_df[feature_return]\n",
    "    if original_feature_drop_boolean: df.drop(['Cabin'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def name_title(df, feature_return, original_feature_drop_boolean='True'):\n",
    "    p_df = df.copy()\n",
    "    list_title_origin = list(map(lambda x:x.split('.')[0].split(' ')[-1],list(df['Name'])))\n",
    "    list_title = []\n",
    "    for title in list_title_origin:\n",
    "        if title not in ['Mr', 'Miss', 'Mrs', 'Master']: title = np.nan\n",
    "        list_title.append(title)\n",
    "    p_df[feature_return] = list_title\n",
    "    if original_feature_drop_boolean: p_df.drop(['Name'], axis=1, inplace=True)\n",
    "    return p_df\n",
    "\n",
    "def age_to_int(df, feature_return, original_feature_drop_boolean='True'):\n",
    "    p_df = df.copy()\n",
    "    p_df['Age_check'] = p_df['Age'].copy()\n",
    "    p_df.loc[p_df['Age'].notna(), 'Age_check'] = list(map(lambda x: (x-math.trunc(x))>0, p_df.loc[p_df['Age'].notna(), 'Age_check']))\n",
    "    p_df.loc[p_df['Age'].isna(), 'Age_check'] = False\n",
    "    p_df[feature_return] = p_df['Age'].copy()\n",
    "    p_df.loc[p_df['Age_check'], feature_return] = np.nan\n",
    "    df[feature_return] = p_df[feature_return].copy()\n",
    "    if original_feature_drop_boolean: df.drop(['Age'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def scaling(df, feature_list, scaler_option='minmax', original_feature_drop_boolean='True'):\n",
    "    if scaler_option == 'std': scaler = preprocessing.StandardScaler()\n",
    "    else: scaler = preprocessing.MinMaxScaler()\n",
    "    p_df = df.copy()\n",
    "    for feature in feature_list:\n",
    "        p_df[feature + '_scaled'] = scaler.fit_transform(np.array(df[feature]).reshape(-1,1))\n",
    "    if original_feature_drop_boolean: p_df.drop(feature_list, axis=1, inplace=True)\n",
    "    return p_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "# Cabin: 앞 알파벳과 뒤 숫자 분리 후 one hot encoding\n",
    "# Age: 소수점 있는 Data들 NaN 처리 후 int로 변경\n",
    "# Name: 중간에 직위만 남기기 / {'Mr': 517, 'Mrs': 125, 'Miss': 182, 'Master': 40, 'Don': 1, 'Rev': 6, 'Dr': 7, 'Mme': 1, 'Ms': 1, 'Major': 2, 'Lady': 1, 'Sir': 1, 'Mlle': 2, 'Col': 2, 'Capt': 1, 'Countess': 1, 'Jonkheer': 1}\n",
    "# Ticket: 고민 필요\n",
    "df_train = df_train_raw.copy()\n",
    "df_train = cabin_only_letter(df_train, 'Cabin_str')\n",
    "df_train = name_title(df_train, 'Name_title')\n",
    "df_train = age_to_int(df_train, 'Age_int')\n",
    "df_train = scaling(df_train, ['Age_int', 'Fare'])\n",
    "df_train = one_hot_encoding(df_train, ['Embarked', 'Cabin_str', 'Name_title', 'Sex'], method='pandas', nan_drop_boolean=True)\n",
    "df_train = df_train.drop(['PassengerId', 'Ticket'], axis=1)\n",
    "\n",
    "df_test = df_test_raw.copy()\n",
    "df_test = cabin_only_letter(df_test, 'Cabin_str')\n",
    "df_test = name_title(df_test, 'Name_title')\n",
    "df_test = age_to_int(df_test, 'Age_int')\n",
    "df_test = scaling(df_test, ['Age_int', 'Fare'])\n",
    "df_test = one_hot_encoding(df_test, ['Embarked', 'Cabin_str', 'Name_title', 'Sex'], method='pandas', nan_drop_boolean=True)\n",
    "df_test = df_test.drop(['PassengerId', 'Ticket'], axis=1)\n",
    "\n",
    "df_train.to_csv('train_hongkyu.csv')\n",
    "df_test.to_csv('test_hongkyu.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "machine_learning",
   "language": "python",
   "display_name": "python3_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}